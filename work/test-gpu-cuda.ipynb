{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# GPU/CUDA Diagnostic Test\n",
        "\n",
        "Run each cell in order to diagnose the GPU detection issue.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Check Environment Variables\n",
        "import os\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"KERNEL ENVIRONMENT VARIABLES\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "env_vars = {\n",
        "    'LD_LIBRARY_PATH': os.environ.get('LD_LIBRARY_PATH', 'NOT SET'),\n",
        "    'CUDA_HOME': os.environ.get('CUDA_HOME', 'NOT SET'),\n",
        "    'CUDA_ROOT': os.environ.get('CUDA_ROOT', 'NOT SET'),\n",
        "    'CUDA_PATH': os.environ.get('CUDA_PATH', 'NOT SET'),\n",
        "    'NVIDIA_VISIBLE_DEVICES': os.environ.get('NVIDIA_VISIBLE_DEVICES', 'NOT SET'),\n",
        "    'CUDA_VISIBLE_DEVICES': os.environ.get('CUDA_VISIBLE_DEVICES', 'NOT SET'),\n",
        "}\n",
        "\n",
        "for key, value in env_vars.items():\n",
        "    if len(str(value)) > 100:\n",
        "        print(f\"{key}: {value[:100]}...\")\n",
        "    else:\n",
        "        print(f\"{key}: {value}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "if env_vars['LD_LIBRARY_PATH'] == 'NOT SET':\n",
        "    print(\"‚ùå PROBLEM: LD_LIBRARY_PATH not set in kernel!\")\n",
        "    print(\"   The kernel config is not being applied.\")\n",
        "else:\n",
        "    print(\"‚úì LD_LIBRARY_PATH is set\")\n",
        "\n",
        "if env_vars['NVIDIA_VISIBLE_DEVICES'] == 'NOT SET':\n",
        "    print(\"‚ùå PROBLEM: NVIDIA_VISIBLE_DEVICES not set!\")\n",
        "elif env_vars['NVIDIA_VISIBLE_DEVICES'] == 'void':\n",
        "    print(\"‚ùå PROBLEM: NVIDIA_VISIBLE_DEVICES=void (hides GPU!)\")\n",
        "else:\n",
        "    print(f\"‚úì NVIDIA_VISIBLE_DEVICES: {env_vars['NVIDIA_VISIBLE_DEVICES']}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Check nvidia-smi\n",
        "import subprocess\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"NVIDIA-SMI CHECK\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    result = subprocess.run(['nvidia-smi', '-L'], capture_output=True, text=True, timeout=5)\n",
        "    print(result.stdout)\n",
        "    if result.returncode == 0 and 'GPU' in result.stdout:\n",
        "        print(\"‚úì nvidia-smi can see GPU\")\n",
        "    else:\n",
        "        print(\"‚ùå nvidia-smi failed or no GPU found\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error running nvidia-smi: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: PyTorch CUDA Check (BEFORE init)\n",
        "import torch\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"PYTORCH CUDA (BEFORE INIT)\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA compiled version: {torch.version.cuda}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"Device count: {torch.cuda.device_count()}\")\n",
        "\n",
        "if not torch.cuda.is_available():\n",
        "    print(\"\\n‚ùå PyTorch cannot see CUDA\")\n",
        "    print(\"   Will try forced initialization next...\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Force CUDA Initialization\n",
        "print(\"=\" * 60)\n",
        "print(\"FORCING CUDA INITIALIZATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    torch.cuda.init()\n",
        "    print(\"‚úì torch.cuda.init() succeeded\")\n",
        "    print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "    print(f\"Device count: {torch.cuda.device_count()}\")\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"‚úì GPU: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"‚úì Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "        print(\"\\nüéâ SUCCESS! GPU is working!\")\n",
        "    else:\n",
        "        print(\"\\n‚ùå Init succeeded but CUDA still not available\")\n",
        "        \n",
        "except RuntimeError as e:\n",
        "    print(f\"‚ùå torch.cuda.init() FAILED: {e}\")\n",
        "    print(\"\\nThis means PyTorch cannot initialize CUDA.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Low-level CUDA Runtime Check\n",
        "import ctypes\n",
        "\n",
        "print(\"=\" * 60)\n",
        "print(\"LOW-LEVEL CUDA RUNTIME CHECK\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    libcuda = ctypes.CDLL(\"/usr/lib/x86_64-linux-gnu/libcuda.so.1\")\n",
        "    print(\"‚úì libcuda.so.1 loaded\")\n",
        "    \n",
        "    # Try cuInit\n",
        "    result = libcuda.cuInit(0)\n",
        "    print(f\"cuInit result: {result} \", end=\"\")\n",
        "    \n",
        "    if result == 0:\n",
        "        print(\"(‚úì SUCCESS)\")\n",
        "        \n",
        "        # Try getting device count\n",
        "        count = ctypes.c_int()\n",
        "        result = libcuda.cuDeviceGetCount(ctypes.byref(count))\n",
        "        print(f\"cuDeviceGetCount result: {result} \", end=\"\")\n",
        "        \n",
        "        if result == 0:\n",
        "            print(f\"(‚úì SUCCESS)\")\n",
        "            print(f\"GPU count from CUDA runtime: {count.value}\")\n",
        "        else:\n",
        "            print(f\"(‚ùå FAILED)\")\n",
        "            \n",
        "    elif result == 100:\n",
        "        print(\"(‚ùå CUDA_ERROR_NO_DEVICE)\")\n",
        "        print(\"\\nDiagnosis: CUDA driver can't see devices\")\n",
        "        print(\"Likely cause: NVIDIA_VISIBLE_DEVICES=void or permissions issue\")\n",
        "    elif result == 3:\n",
        "        print(\"(‚ùå CUDA_ERROR_NOT_INITIALIZED)\")\n",
        "    else:\n",
        "        print(f\"(‚ùå Unknown error code: {result})\")\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Test Unsloth Import\n",
        "print(\"=\" * 60)\n",
        "print(\"UNSLOTH IMPORT TEST\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "try:\n",
        "    from unsloth import FastLanguageModel\n",
        "    print(\"‚úÖ SUCCESS! Unsloth imported successfully!\")\n",
        "    print(\"GPU is working and Unsloth can use it.\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Unsloth import FAILED: {e}\")\n",
        "    print(\"\\nThis is expected if GPU detection failed in previous cells.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Interpretation\n",
        "\n",
        "**If Cell 1 shows `LD_LIBRARY_PATH: NOT SET`:**\n",
        "- The kernel configuration is not being applied\n",
        "- Need to restart container with volume removed: `docker-compose down && docker volume rm unsloth-launch_unsloth-home && docker-compose up -d`\n",
        "\n",
        "**If Cell 1 shows `NVIDIA_VISIBLE_DEVICES: void`:**\n",
        "- This explicitly hides GPUs from the process\n",
        "- The docker-compose.yml needs to NOT set this variable\n",
        "- Docker's NVIDIA runtime should handle it automatically\n",
        "\n",
        "**If Cell 5 shows `cuInit result: 100` (CUDA_ERROR_NO_DEVICE):**\n",
        "- CUDA runtime cannot see devices\n",
        "- Usually caused by NVIDIA_VISIBLE_DEVICES=void\n",
        "- Or container not started with proper GPU access\n",
        "\n",
        "**If Cell 4 succeeds:**\n",
        "- GPU is working! Unsloth should work in Cell 6.\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
